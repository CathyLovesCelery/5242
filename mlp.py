# -*- coding: utf-8 -*-
"""mlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/160ES-t_GbRs4IwybHXzk7b0s-xwV4kCw
"""

import os
import pandas as pd
import torch
import torch.nn as nn
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

# Set paths
base_dir = '/content/drive/My Drive/CS5242_2025_codes/group_project/food_split'
label_file = os.path.join(base_dir, 'labels.csv')

# Load labels
labels_df = pd.read_csv(label_file)

# Helper: load label df for a specific split
def get_split_df(split_name):
    image_dir = os.path.join(base_dir, split_name)
    image_names = set(os.listdir(image_dir))
    return labels_df[labels_df['filename'].isin(image_names)].reset_index(drop=True)

# def get_split_df(split_name):
#     image_dir = os.path.join(base_dir, split_name)
#     image_names = set(os.listdir(image_dir))

#     # Filter by split and by label range [1, 10]
#     filtered_df = labels_df[
#         (labels_df['filename'].isin(image_names)) &
#         (labels_df['label'].between(1, 10))
#     ].reset_index(drop=True)

#     return filtered_df

class FoodDataset(Dataset):
    def __init__(self, df, img_dir, transform=None):
        self.df = df
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_name = self.df.loc[idx, 'filename']
        label = self.df.loc[idx, 'label']
        img_path = os.path.join(self.img_dir, img_name)
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(label, dtype=torch.int64)

transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
])

# Load splits
train_df = get_split_df('train')
val_df = get_split_df('validation')
test_df = get_split_df('test')

train_dataset = FoodDataset(train_df, os.path.join(base_dir, 'train'), transform=transform)
val_dataset = FoodDataset(val_df, os.path.join(base_dir, 'validation'), transform=transform)
test_dataset = FoodDataset(test_df, os.path.join(base_dir, 'test'), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

print("Max label in training set:", train_df['label'].max())
print("Unique labels:", train_df['label'].nunique())

class MLP(nn.Module):
    def __init__(self, input_dim=64*64*3, num_classes=96):
        super(MLP, self).__init__()
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(input_dim, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.model(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = MLP(input_dim=64*64*3, num_classes=96).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 20

best_val_acc = 0.0

for epoch in range(num_epochs):
    # -------- Training --------
    model.train()
    total_train_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_train_loss += loss.item()

    # -------- Validation --------
    model.eval()
    correct = 0
    total = 0
    val_loss = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    val_acc = correct / total
    avg_val_loss = val_loss / len(val_loader)

    print(f"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {total_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}")

    # Save best model
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), "best_mlp_model.pth")
        print("âœ… Saved Best Model")

# Load the best model
model.load_state_dict(torch.load("best_mlp_model.pth"))

# -------- Test --------
model.eval()
correct = 0
total = 0
test_loss = 0

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        test_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

test_acc = correct / total
avg_test_loss = test_loss / len(test_loader)

print(f"Test Loss: {avg_test_loss:.4f}, Test Acc: {test_acc:.4f}")